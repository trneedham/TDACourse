{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bottleneck Distance Demonstration\n",
    "\n",
    "In this notebook, we explore more persistence diagrams and compute distances between them using bottleneck distance. We will also use bottleneck distance between persistence diagrams to do a simple shape classification experiment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import standard packages for TDA\n",
    "from ripser import ripser\n",
    "from ripser import Rips\n",
    "import persim\n",
    "from persim import plot_diagrams \n",
    "import matplotlib.pyplot as pl\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "\n",
    "# Import packages for loading .mat files\n",
    "import os \n",
    "from os.path import dirname, join as pjoin\n",
    "import scipy.io as sio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First we need to load the data set. The data consists of a large number of densely sampled plane curves representing various objects (bones, dogs, cars, etc.). The file is a .mat file, which we read into Python with the following commands."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.getcwd() # Get the current working directory name.\n",
    "mat_fname = pjoin(data_dir, 'planarShapes.mat') \n",
    "# Add the file name to the current working directory.\n",
    "\n",
    "mat_contents = sio.loadmat(mat_fname) # Read the file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what is contained in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we need to separate the actual data from the metadata. The types of data in the file are listed under several \"keys\". "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mat_contents.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The plane curves we are after are under the 'planarShapes' key. Let's extract that from the mat file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "planarShapes = mat_contents['planarShapes']\n",
    "planarShapes.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second command above shows that planarShapes is a 2x100x1300 array. Exploring more, we would find that there are 1300 separate shapes, separated into 20 copies of similar shapes (so 65 classes of similar shapes). Each of the 1300 shapes is a pointcloud in $\\mathbb{R}^2$ consisting of 100 points. Let's plot a couple of the shapes below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape1 = planarShapes[:,:,125] # Pick some shapes.\n",
    "shape2 = planarShapes[:,:,127]\n",
    "shape3 = planarShapes[:,:,1]\n",
    "\n",
    "# The commands below plot the shape that we picked.\n",
    "fig1 = pl.figure()\n",
    "ax1 = fig1.add_subplot(121)\n",
    "ax1.plot(shape1[0, :], shape1[1, :], 'ob');\n",
    "ax1.axis('equal');\n",
    "fig2 = pl.figure()\n",
    "ax2 = fig2.add_subplot(121)\n",
    "ax2.plot(shape2[0, :], shape2[1, :], 'ob');\n",
    "ax2.axis('equal');\n",
    "fig3 = pl.figure()\n",
    "ax3 = fig3.add_subplot(121)\n",
    "ax3.plot(shape3[0, :], shape3[1, :], 'ob');\n",
    "ax3.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's compute persistence diagrams for these examples, then look at bottleneck distances between them. Note that ripser prefers the pointclouds to be transposed. I.e., shape1 is given as a 2x100 array, but ripser wants to see a 100x2 array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape1Dgm = ripser(np.transpose(shape1))['dgms'] \n",
    "shape2Dgm = ripser(np.transpose(shape2))['dgms']\n",
    "shape3Dgm = ripser(np.transpose(shape3))['dgms']\n",
    "\n",
    "fig1 = pl.figure()\n",
    "plot_diagrams(shape1Dgm)\n",
    "fig2 = pl.figure()\n",
    "plot_diagrams(shape2Dgm)\n",
    "fig3 = pl.figure()\n",
    "plot_diagrams(shape3Dgm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The \"persim\" package includes several distance metrics between persistence diagrams, including the bottleneck distance that we have defined in class. Let's compute bottleneck distances between our shape examples. There is an option to not only compute the distance, but to record the optimal matching which produces it. In the first example, we compute the bottleneck distance between the degree 1 persistence diagrams for shape1 and shape2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_bottleneck, (matching, D) = persim.bottleneck(shape1Dgm[1], shape2Dgm[1], matching=True)\n",
    "print(distance_bottleneck)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then plot the persistence diagrams on the same axes and display the optimal matching. The green line segment indicates matched points. All other points are matched with the diagonal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persim.plot.bottleneck_matching(shape1Dgm[1], shape2Dgm[1], matching, D, labels=['shape1', 'shape2'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also compute the distance between shape2 and shape3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_bottleneck, (matching, D) = persim.bottleneck(shape2Dgm[1], shape3Dgm[1], matching=True)\n",
    "print(distance_bottleneck)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that shape1 and shape2 came from the same class of shapes, whereas shape 3 comes from a different class. This is reflected in the fact that the distance here is much larger than the distance between shape1 and shape2. When we plot the matching, we see that points which are much farther apart must get matched together. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "persim.plot.bottleneck_matching(shape2Dgm[1], shape3Dgm[1], matching, D, labels=['shape2', 'shape3'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So bottleneck distance seems to pick up on differences in the shapes. This suggests that we could try a simple classification experiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification Experiment\n",
    "For our experiment, we will extract some small number of shapes from the total collection. We would also prefer to have a list of 2x100 arrays, rather than a big 2x100x1300 arrays. Finally, ripser uses a 100x2 format, so we should transpose all of our arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shape_classes = [0,100,200,300,400,500] # Pick indices of shape classes to sample.\n",
    "num_shapes = 5 # Pick number of examples to take from each shape class\n",
    "\n",
    "# List all indices of the shape samples for the experiment.\n",
    "samples =[]\n",
    "for j in range(len(shape_classes)):\n",
    "    samples = samples+range(shape_classes[j],shape_classes[j]+num_shapes)\n",
    "\n",
    "# We now pick out the shapes with indices in 'samples' and preprocess.\n",
    "num_samp = len(samples)\n",
    "shapeSamples = range(num_samp)\n",
    "\n",
    "for j in range(num_samp):\n",
    "    shape = planarShapes[:,:,samples[j]]\n",
    "    shapeSamples[j] = np.transpose(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at shapes from each of the shape classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(shape_classes)):\n",
    "    shape_example = planarShapes[:,:,shape_classes[j]]\n",
    "    figName = 'fig'+str(j)\n",
    "    axName = 'ax'+str(j)\n",
    "\n",
    "    figName = pl.figure()\n",
    "    axName = figName.add_subplot(121)\n",
    "    axName.plot(shape_example[0, :], shape_example[1, :], 'ob');\n",
    "    axName.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also look at the samples within a given class of shapes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(num_shapes):\n",
    "    shape_example = planarShapes[:,:,shape_classes[0]+j]\n",
    "    figName = 'fig'+str(j)\n",
    "    axName = 'ax'+str(j)\n",
    "\n",
    "    figName = pl.figure()\n",
    "    axName = figName.add_subplot(121)\n",
    "    axName.plot(shape_example[0, :], shape_example[1, :], 'ob');\n",
    "    axName.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next we compute persistence diagrams for each of the shapes in our sampled collection. We are using the standard options for ripser, which will compute degree-0 and degree-1 persistence diagrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shapeSamplesDgms = range(0,num_samp)\n",
    "\n",
    "for j in range(len(samples)):\n",
    "    shapeSamplesDgms[j] = ripser(shapeSamples[j])['dgms']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now compute bottleneck distances between all pairs of persistence diagrams. We computed persistence diagrams for degree-0 and degree-1 persistent homology in the previous cell, so we could compute bottleneck distances in each degree.\n",
    "\n",
    "It takes quite a while to run the degree-0 computation. It is commented out in the cell below because I don't want to run it in class. Feel free to uncomment and try it yourself.\n",
    "\n",
    "In the cell below that, we compute the distance matrix for the degree-1 persistence diagrams. Note that, if there are N total shape samples, then this distance matrix should be an NxN symmetric matrix. The $(i,j)$-entry is the bottleneck distance between the persistence diagram of shape $i$ and shape $j$. We are really thinking of each shape as a point in a metric space!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#distMatDeg0 = np.zeros([num_samp,num_samp])\n",
    "\n",
    "#for j in range(num_samp):\n",
    "#    for k in range(j+1,num_samp):\n",
    "#        distMatDeg0[j,k] = persim.bottleneck(shapeSamplesDgms[j][0], shapeSamplesDgms[k][0])\n",
    "#    print(j)\n",
    "\n",
    "#distMatDeg0 = distMatDeg0 + np.transpose(distMatDeg0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distMatDeg1 = np.zeros([num_samp,num_samp])\n",
    "\n",
    "for j in range(num_samp):\n",
    "    for k in range(j+1,num_samp):\n",
    "        distMatDeg1[j,k] = persim.bottleneck(shapeSamplesDgms[j][1], shapeSamplesDgms[k][1])\n",
    "\n",
    "distMatDeg1 = distMatDeg1 + np.transpose(distMatDeg1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the structure of our metric space, we can take a look at the distance matrix. Once the matrix gets large enough, it becomes uninformative to look at the actual numbers. Typically it is easier to look at a color-coded picture of the distance matrix, which we do below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure()\n",
    "pl.subplot(121)\n",
    "pl.imshow(distMatDeg1)\n",
    "pl.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To understand the structure of our metric space more fully, we can try dimension reduction and visualization techniques. Here we will use an algorithm called 'multidimensional scaling'. This will take our \\emph{abstract} finite metric space (which doesn't naturally live in any Euclidean space), and find the most faithful representation as a finite subset of $\\mathbb{R}^n$, for whichever $n$ we choose (typically $n=2$ or $3$ so that we can visualize the result). Here 'most faithful' means that the resulting Euclidean set should have a distance matrix which is as close as possible to the one picture above.\n",
    "\n",
    "First we will use multidimensional scaling to represent our abstract metric space as a subset of the plane."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a package containing the MDS algorithm and set options for the algorithm\n",
    "from sklearn import manifold\n",
    "mds = manifold.MDS(n_components=2, dissimilarity=\"precomputed\", random_state=6)\n",
    "\n",
    "# Compute MDS and extract the coordinates of the points\n",
    "results = mds.fit(distMatDeg1)\n",
    "coords = results.embedding_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot the MDS representation of our metric space. The points are color-coded by shape class. We see that there is some reasonably nice clustering of the points---points from the same shape class tend to lie closer together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1 = pl.figure()\n",
    "ax1 = fig1.add_subplot(111)\n",
    "\n",
    "for j in range(len(shape_classes)+1):\n",
    "    R = range((j-1)*num_shapes,j*num_shapes)\n",
    "    ax1.plot(coords[R, 0], coords[R, 1],'o');\n",
    "    ax1.axis('equal');\n",
    "\n",
    "# Add labels to indicate which color corresponds to each shape class\n",
    "for i in range(len(shape_classes)):\n",
    "    ax1.annotate(str(i), (coords[i*num_shapes,0], coords[i*num_shapes,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also run MDS to represent our metric space in $\\mathbb{R}^3$. To me this doesn't seem to drastically change the clustering behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mds = manifold.MDS(n_components=3, dissimilarity=\"precomputed\", random_state=6)\n",
    "\n",
    "# Compute MDS and extract the coordinates of the points\n",
    "results = mds.fit(distMatDeg1)\n",
    "coords = results.embedding_\n",
    "\n",
    "fig = pl.figure()\n",
    "ax = Axes3D(fig)\n",
    "\n",
    "for j in range(len(shape_classes)+1):\n",
    "    R = range((j-1)*num_shapes,j*num_shapes)\n",
    "    ax.scatter(coords[R,0],coords[R,1],coords[R,2], marker='o');\n",
    "    ax.set_aspect('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visually it appears that shape class 5 is the only one that is not realy clustered very well. Let's take a look at the shapes in that class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "worst_cluster_index = 5\n",
    "\n",
    "for j in range(num_shapes):\n",
    "    shape_example = planarShapes[:,:,shape_classes[worst_cluster_index]+j]\n",
    "    figName = 'fig'+str(j)\n",
    "    axName = 'ax'+str(j)\n",
    "\n",
    "    figName = pl.figure()\n",
    "    axName = figName.add_subplot(121)\n",
    "    axName.plot(shape_example[0, :], shape_example[1, :], 'ob');\n",
    "    axName.axis('equal');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also look at a clustering dendrogram for the distance matrix to get more of an idea about how the points are clustered in the metric space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.cluster import hierarchy\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# The linkage function was giving me a warning (but still computing) that I couldn't figure out.\n",
    "# I supressed these warnings with the function above. This is not recommended in general!\n",
    "linkage = hierarchy.linkage(distMatDeg1, 'single')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we plot the dendrogram, we see that there is some distinct clustering. The shapes are roughly clustered by class, although not perfectly. We could get quanitative descriptions of the clustering behavior (e.g., by nearest neighbor classification rate)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pl.figure()\n",
    "dn = hierarchy.dendrogram(linkage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
